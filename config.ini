[DEFAULT]
;The data is not available on github, please contact Dr. Milica Gaisc {mg436@cam.ac.uk} for data sharing
raw_labelled_data_dir = Data/labelled_posts
raw_unlabelled_data_dir = Data/unlabelled_posts
;all kinds of output results and models are saved in this directory
save_dir = tmpfile

plot_every_steps = 10
early_stopping_tolerance = 30
max_grad_norm = 5
init_learning_rate = 0.001
min_learning_rate = 0.0001
decay_rate = 0.986
total_steps = 4000
dropout_rate = 0.8
cross_validation = 10
batch_size = 24
l2_normalisation = 0.0001

vocabulary_filepath = Data/vocab_dict.json
reversed_vocabulary_filepath = Data/reversed_vocab_dict.json
labelled_data_filepath = Data/NAUM_labelled_data.json



[GloVe]
training_data_filepath = Data/training_data_for_GloVe.txt
total_epochs = 15


[CNN_GloVe]
problem_max_length = 335
negative_take_max_length = 118
fnn_hidden_size = 150
feature_map = 50
;len(filter_windows) can only be 3. e.g. [3,4,5]. you can change it as you want
filter_windows = [2, 3, 4]
;dont save model ckpt due to large external memeory consuming, just save result files.
is_model_save = False



[SkipThought]
training_data_filepath = Data/training_data_for_SkipThought.json
;you can set it as much as you want, because we only use sentence embedding
word_feature_size = 300
;one sentence contain at most 50 words in our paper
max_length = 50
total_epochs = 2
decay_rate = 0.95
init_learning_rate = 0.003
min_learning_rate = 0.0001
plot_every_steps = 100
update_lr_every_steps = 1000



[GRU_SkipThought]
;number of sentences one doc can contain at most
max_length = 25
fnn_hidden_size=150
gru_hidden_size=150
is_model_save = False




[PVDM]
training_data_filepath = Data/training_data_for_PVDM.json



[FNN_PVDM]
fnn_hidden_size = 800
is_model_save = False



[LR_BOW]
l2_normalisation = 0.1


[SVM_BOW]
kernel = rbf
gamma = 0.01
